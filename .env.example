# Ambiente de execução (development, production, test)
NODE_ENV=development

# Servidor
# Porta em que o servidor irá escutar
PORT=3333

# Host/IP onde o servidor irá escutar (0.0.0.0 = todas as interfaces)
HOST=0.0.0.0

# Logger
# Nível de log (trace, debug, info, warn, error, fatal)
LOG_LEVEL=info

# Diretório onde os logs serão salvos em produção
LOGS_DIR=logs

# CORS Configuration
# Para permitir todas as origens (não recomendado em produção):
# CORS_ORIGINS=true

# Para permitir origens específicas (recomendado):
# CORS_ORIGINS=http://localhost:3000,http://localhost:5173,https://example.com

# Não definir CORS_ORIGINS bloqueará todas as origens (padrão seguro)
CORS_ORIGINS=http://localhost:3000

# Rate Limiting
# Máximo de requisições permitidas por IP na janela de tempo
RATE_LIMIT_MAX=100

# Janela de tempo para rate limiting (exemplos: '1 minute', '15 minutes', '1 hour')
RATE_LIMIT_TIME_WINDOW=1 minute

# Session Secret
# Chave secreta para criptografar sessões (mínimo 32 bytes em hexadecimal = 64 caracteres)
# IMPORTANTE: Gere uma nova chave aleatória para produção usando:
# node -e "console.log(require('crypto').randomBytes(32).toString('hex'))"
SESSION_SECRET=0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef

# Compression
# Tamanho mínimo em bytes para ativar compressão de respostas (1024 = 1KB)
# Respostas menores que este valor não serão comprimidas
COMPRESS_THRESHOLD=1024

# Upload de arquivos
# Tamanho máximo por arquivo em bytes (10485760 = 10MB)
UPLOAD_MAX_FILE_SIZE=10485760

# Número máximo de arquivos por requisição
UPLOAD_MAX_FILES=5

# Tipos MIME permitidos (separados por vírgula)
UPLOAD_ALLOWED_MIMES=image/jpeg,image/png,image/webp,application/pdf

# Diretório onde os arquivos enviados serão salvos
UPLOAD_STORAGE_PATH=./uploads

# ETags para cache HTTP
# Algoritmo de hash para gerar ETags
# sha1 = mais rápido (recomendado para maioria dos casos)
# sha256 = mais seguro (uso em ambientes de alta segurança)
# md5 = compatibilidade legada (não recomendado)
ETAG_ALGORITHM=sha1

# Gerar ETags fracos (W/"...")
# false = ETags fortes (padrão, recomendado) - compara byte por byte
# true = ETags fracos - permite comparação semântica (conteúdo equivalente)
ETAG_WEAK=false

# Under Pressure - Monitoramento de saúde do servidor (APENAS PRODUÇÃO)
# Delay máximo do event loop em ms antes de retornar 503
# 1000ms = 1 segundo de bloqueio (servidor sobrecarregado)
# Quanto menor o valor, mais sensível a sobrecarga
UNDER_PRESSURE_MAX_EVENT_LOOP_DELAY=1000

# Uso máximo de memória heap em bytes antes de retornar 503
# 104857600 bytes = 100MB (padrão para VPS pequenas)
# Ajuste conforme a memória disponível do servidor
UNDER_PRESSURE_MAX_HEAP_USED_BYTES=104857600

# Uso máximo de memória RSS em bytes antes de retornar 503
# RSS = Resident Set Size (memória total usada pelo processo)
# 209715200 bytes = 200MB (padrão para VPS pequenas)
# Ajuste conforme a memória disponível do servidor
UNDER_PRESSURE_MAX_RSS_BYTES=209715200

# Event Loop Utilization máximo antes de retornar 503
# 0.98 = 98% ocupado (apenas 2% de tempo livre)
# Valores entre 0.95-0.98 são recomendados
UNDER_PRESSURE_MAX_EVENT_LOOP_UTILIZATION=0.98

# Intervalo de verificação de saúde em ms
# 5000ms = 5 segundos (padrão)
# Valores menores detectam sobrecarga mais rápido, mas consomem mais CPU
UNDER_PRESSURE_HEALTH_CHECK_INTERVAL=5000

# Metrics - Prometheus (APENAS PRODUÇÃO)
# IMPORTANTE: Servidor de métricas roda em PORTA SEPARADA para isolamento de segurança
# Configure firewall para NÃO expor esta porta publicamente (apenas para Prometheus)

# Porta separada para servidor de métricas (padrão: 9090)
# NUNCA exponha esta porta publicamente! Apenas para rede interna/Prometheus
# Configure firewall: permitir 9090 apenas do IP do Prometheus
METRICS_PORT=9090

# Endpoint onde as métricas serão expostas no formato Prometheus
METRICS_ENDPOINT=/metrics

# Coletar métricas padrão do Node.js (CPU, memória, event loop, etc.)
# true = coleta métricas do processo (recomendado)
# false = desabilita métricas padrão (não recomendado)
METRICS_DEFAULT_METRICS_ENABLED=true

# Coletar métricas de rotas HTTP (latência, throughput, status codes, erros)
# true = coleta métricas por rota (recomendado)
# false = desabilita métricas de rotas
METRICS_ROUTE_METRICS_ENABLED=true

# IP Whitelist para o endpoint de métricas (ALTAMENTE RECOMENDADO)
# IMPORTANTE: Métricas expõem informações sensíveis da infraestrutura!
# Lista de IPs separados por vírgula que podem acessar /metrics
# Deixe vazio para permitir todos os IPs (NÃO RECOMENDADO em produção)
#
# Exemplos de configuração:
# - Servidor Prometheus local: METRICS_ALLOWED_IPS=127.0.0.1
# - Prometheus na mesma rede: METRICS_ALLOWED_IPS=10.0.1.5
# - Múltiplos servidores: METRICS_ALLOWED_IPS=127.0.0.1,10.0.1.5,192.168.1.100
# - IPv6: METRICS_ALLOWED_IPS=::1,2001:db8::1
#
# Como descobrir o IP do Prometheus:
# 1. No servidor Prometheus, execute: curl ifconfig.me
# 2. Ou veja nos logs quando ele tentar acessar /metrics (será bloqueado primeiro)
METRICS_ALLOWED_IPS=127.0.0.1,::1

# Circuit Breaker - Proteção contra falhas em cascata
# Implementa o padrão Circuit Breaker para chamadas a serviços externos
# Evita que falhas externas derrubem seu servidor (fail-fast)
#
# Estados do circuito:
# - CLOSED: Normal (requisições passam)
# - OPEN: Serviço externo falhando (rejeita imediatamente sem chamar)
# - HALF-OPEN: Testando se serviço voltou (permite 1 requisição de teste)
#
# Número de falhas consecutivas antes de abrir o circuito
# 5 = após 5 falhas seguidas, o circuito abre e para de chamar o serviço
# Valores menores = mais sensível (abre mais rápido)
# Valores maiores = mais tolerante a falhas intermitentes
CIRCUIT_BREAKER_THRESHOLD=5

# Timeout em ms para considerar uma requisição como falha
# 10000ms = 10 segundos (se serviço externo não responder em 10s, conta como falha)
# Ajuste conforme a latência esperada do serviço externo
# APIs lentas: 15000-30000ms
# APIs rápidas: 3000-5000ms
CIRCUIT_BREAKER_TIMEOUT=10000

# Tempo em ms que o circuito fica OPEN antes de tentar HALF-OPEN
# 30000ms = 30 segundos (após abrir, aguarda 30s antes de testar novamente)
# Tempo de "cooldown" para o serviço externo se recuperar
# Serviços que se recuperam rápido: 10000-20000ms
# Serviços que demoram a se recuperar: 60000-120000ms
CIRCUIT_BREAKER_RESET_TIMEOUT=30000

# Redis - Cache distribuído (OPCIONAL)
# IMPORTANTE: Redis só é necessário se você tiver MÚLTIPLAS instâncias do servidor
# Para desenvolvimento ou servidor único, deixe REDIS_ENABLED=false
#
# Benefícios do Redis:
# - Cache compartilhado entre múltiplas instâncias do servidor
# - Persistência do cache (não perde ao reiniciar)
# - Alta performance e escalabilidade
#
# Habilitar conexão com Redis
# false = usa cache em memória local (padrão, recomendado para desenvolvimento)
# true = conecta ao Redis (recomendado para produção com múltiplas instâncias)
REDIS_ENABLED=false

# Host do servidor Redis (se REDIS_ENABLED=true)
REDIS_HOST=localhost

# Porta do servidor Redis
REDIS_PORT=6379

# Senha do Redis (deixe vazio se não tiver senha configurada)
REDIS_PASSWORD=

# Database do Redis (0-15)
# Use databases diferentes para ambientes diferentes (dev=0, staging=1, prod=2)
REDIS_DB=0

# Caching - Sistema de cache HTTP
# Cacheia respostas de rotas GET para reduzir carga do servidor e melhorar performance
#
# Habilitar sistema de cache
# true = ativa cache (recomendado)
# false = desativa cache completamente
CACHE_ENABLED=true

# TTL (Time To Live) padrão do cache em segundos
# 300 segundos = 5 minutos
# Rotas podem sobrescrever este valor individualmente
# Valores comuns:
# - Dados que mudam pouco: 600-3600 (10 min a 1 hora)
# - Dados que mudam moderadamente: 60-300 (1 a 5 minutos)
# - Dados que mudam frequentemente: 10-60 (10 segundos a 1 minuto)
CACHE_TTL_DEFAULT=300

# Máximo de items em cache (apenas para cache em memória, não afeta Redis)
# 100 = máximo de 100 respostas diferentes cacheadas simultaneamente
# Quando atingir o limite, remove o item mais antigo (FIFO)
# Ajuste conforme memória disponível do servidor
CACHE_MAX_SIZE=100

# Virus Scanning - Proteção contra malware em uploads
# IMPORTANTE: Requer ClamAV instalado ou rodando via Docker
# Para ativar: docker-compose up -d clamav (aguarde ~2min para baixar definições)
#
# Habilitar scanning de vírus em uploads
# false = desabilitado (padrão, sem ClamAV)
# true = habilitado (requer ClamAV rodando)
VIRUS_SCANNING_ENABLED=false

# Host do ClamAV daemon (se VIRUS_SCANNING_ENABLED=true)
# localhost = ClamAV rodando na mesma máquina
# ou IP/hostname do servidor ClamAV
CLAMAV_HOST=localhost

# Porta do ClamAV daemon
# 3310 = porta padrão do clamd (ClamAV daemon)
CLAMAV_PORT=3310

# PostgreSQL - Banco de dados relacional
# IMPORTANTE: Todas as variáveis DB_* são obrigatórias para o servidor iniciar
#
# URL completa de conexão (alternativa moderna - OPCIONAL)
# Formato: postgresql://[user]:[password]@[host]:[port]/[database]?ssl=true
# Exemplo: postgresql://fastify:senha123@localhost:5432/fastify_db
# Se definido, sobrescreve as variáveis DB_* individuais
# DATABASE_URL=postgresql://fastify:senha123@localhost:5432/fastify_db

# Configuração tradicional (OBRIGATÓRIO se não usar DATABASE_URL)
# Host do servidor PostgreSQL
# localhost = PostgreSQL rodando na mesma máquina
# postgres = nome do serviço no Docker Compose
# ou IP/hostname do servidor PostgreSQL
POSTGRES_HOST=localhost

# Porta do PostgreSQL
# 5432 = porta padrão do PostgreSQL
POSTGRES_PORT=5432

# Usuário do banco de dados (OBRIGATÓRIO)
# Para desenvolvimento: qualquer nome
# Para produção: crie um usuário específico com permissões limitadas
POSTGRES_USER=fastify

# Senha do banco de dados (OBRIGATÓRIO)
# IMPORTANTE: Use senhas fortes em produção!
# Gere senhas seguras com: openssl rand -base64 32
POSTGRES_PASSWORD=fastify_dev_password

# Nome do banco de dados (OBRIGATÓRIO)
# O Docker Compose PostgreSQL cria automaticamente este banco
# Criar banco manualmente: psql -U postgres -c "CREATE DATABASE fastify_db;"
POSTGRES_DB=fastify_db

# Habilitar SSL/TLS para conexão com PostgreSQL
# false = sem SSL (padrão, aceito em desenvolvimento)
# true = com SSL (obrigatório em produção)
POSTGRES_SSL=false

# Pool de conexões - Configuração de performance
# Mínimo de conexões mantidas abertas no pool
# 2 = mantém 2 conexões prontas (padrão)
# Valores menores: economizam recursos, mas podem causar latência inicial
# Valores maiores: consomem mais recursos, mas reduzem latência
POSTGRES_POOL_MIN=2

# Máximo de conexões simultâneas no pool
# 10 = máximo de 10 conexões simultâneas (padrão)
# Ajuste conforme:
# - max_connections do PostgreSQL (geralmente 100)
# - Número de instâncias da aplicação
# - Carga esperada
# Exemplo: PostgreSQL com 100 conexões, 5 instâncias do app = 20 por instância
POSTGRES_POOL_MAX=10

# Couchbase - Banco de dados NoSQL para auditoria e histórico
# IMPORTANTE: Couchbase é usado APENAS para logs de auditoria (histórico de mudanças)
# PostgreSQL continua sendo o banco principal para dados transacionais
#
# Benefícios do Couchbase para auditoria:
# - Alta performance e escalabilidade
# - Queries N1QL (SQL para JSON)
# - Suporte a transações ACID
# - Replicação automática e backup
# - Esquema flexível ideal para diferentes tipos de mudanças
#
# Habilitar conexão com Couchbase
# false = auditoria desabilitada (padrão, sem Couchbase)
# true = habilita logs de auditoria (requer Couchbase rodando)
COUCHBASE_ENABLED=false

# URL de conexão do Couchbase
# couchbase://localhost = Couchbase rodando localmente
# couchbase://couchbase.example.com = Couchbase em produção
# couchbases://... = Couchbase com SSL/TLS
COUCHBASE_URL=couchbase://localhost

# Usuário do Couchbase
# Padrão: Administrator (usuário admin criado na instalação)
COUCHBASE_USER=Administrator

# Senha do Couchbase
# IMPORTANTE: Altere a senha padrão em produção!
COUCHBASE_PASSWORD=password

# Nome do bucket onde os logs de auditoria serão armazenados
# O bucket deve ser criado manualmente no Couchbase antes de usar
# Recomendado: audit_logs, change_history, etc.
COUCHBASE_BUCKET=audit_logs

# Scope (OPCIONAL - usa _default se não especificado)
# Scopes permitem organizar collections dentro de um bucket
COUCHBASE_SCOPE=

# Collection (OPCIONAL - usa _default se não especificado)
# Collections são como tabelas dentro de um scope
COUCHBASE_COLLECTION=
